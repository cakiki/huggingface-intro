{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f95a9e09",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-23 19:48:49.514533: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-23 19:48:49.514552: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from huggingface_hub import notebook_login\n",
    "import os\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855fb9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77716564",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center;\">A Whirlwind Tour of the ðŸ¤— Hugging Face Ecosystem</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec11d2af",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39cc27f",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:center;\"><b>Christopher Akiki</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37e4175",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><a href=\"https://huggingface.co\"><img src=\"images/chapter01_hf-ecosystem.png\" width=800></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb9897",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"images/chapter02_hf-libraries.png\" width=1800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdfbbea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center;\">ðŸ¤— Pipelines</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32225148",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa0a34",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers.pipelines import get_supported_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e706de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_supported_tasks())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a712fdfd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "<center><img src=\"images/gewandhaus_review.png\" width=900></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21dcda6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"One of the best orchestra in the world. I came to Leipzig\\\n",
    "            mainly to have one experience with Gewanhaus Leipzig Orchestra. \n",
    "            Under the baton of Maestro Andris Nelsons, Bruckner symphony #8 was so affection. \n",
    "            The acustic and layout of the concert hall is nice.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383d0e7e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868326b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline(\"text-classification\", model='distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891c8038",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = p(text)\n",
    "outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca993ce3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Named-Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aeeba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline(\"ner\", aggregation_strategy=\"simple\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8e4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = p(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf043b0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ae948",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Why did I visit Leipzig?\"\n",
    "outputs = p(question=question, context=text)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4d7e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What music did the orchestra play?\"\n",
    "outputs = p(question=question, context=text)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203bbce4",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0caab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline(\"translation_en_to_de\", model=\"Helsinki-NLP/opus-mt-en-de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4076c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = p(text, clean_up_tokenization_spaces=True)\n",
    "print(outputs[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb6157",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center;\">ðŸ¤— Tokenizers</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdac586",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"images/tokenization_pipeline.svg\" width=1200></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b370ce",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b90e5186",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d39c6f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "moby_dick_raw = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03fc19fc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19 MiB\n"
     ]
    }
   ],
   "source": [
    "size = len(moby_dick_raw.encode())\n",
    "print(f\"{size/1024**2:.2f} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca45ab2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, normalizers, pre_tokenizers, processors\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers.trainers import WordPieceTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "313154cf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "unk_token = \"[UNK]\"\n",
    "pad_token = \"[PAD]\"\n",
    "cls_token = \"[CLS]\" \n",
    "sep_token = \"[SEP]\"\n",
    "mask_token = \"[MASK]\"\n",
    "special_tokens = [unk_token, pad_token, cls_token, sep_token, mask_token]\n",
    "vocab_size = 6_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c87d4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# WordPiece Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ea08735",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "custom_tokenizer = Tokenizer(WordPiece(unk_token=unk_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc53c243",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Sequence of Normalizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce3889c0",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "custom_normalizer = normalizers.Sequence(\n",
    "            [normalizers.NFKD(), normalizers.Lowercase(), normalizers.StripAccents()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebac3da",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Sequence of Pretokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "586aa00b",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "custom_pre_tokenizer = pre_tokenizers.Sequence(\n",
    "            [pre_tokenizers.WhitespaceSplit(), pre_tokenizers.Punctuation()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0bec5b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# WordPiece Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5b3defc",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "custom_trainer = WordPieceTrainer(vocab_size=vocab_size, special_tokens=special_tokens, show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ca3e7df",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "custom_tokenizer.normalizer = custom_normalizer\n",
    "custom_tokenizer.pre_tokenizer = custom_pre_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6e99d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tokenizer.train_from_iterator([moby_dick_raw], trainer=custom_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "351e8730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f9099",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = custom_tokenizer.encode(\"Let us test this tokenizer\")\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78244dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_token_id = custom_tokenizer.token_to_id(cls_token)\n",
    "sep_token_id = custom_tokenizer.token_to_id(sep_token)\n",
    "\n",
    "custom_post_processor = processors.TemplateProcessing(\n",
    "    single=f\"{cls_token}:0 $A:0 {sep_token}:0\",\n",
    "    pair=f\"{cls_token}:0 $A:0 {sep_token}:0 $B:1 {sep_token}:1\",\n",
    "    special_tokens=[(cls_token, cls_token_id), (sep_token, sep_token_id)],\n",
    ")\n",
    "\n",
    "custom_tokenizer.post_processor = custom_post_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29871967",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = custom_tokenizer.encode(\"Let us test this tokenizer\")\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f73fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = custom_tokenizer.encode(\"This is the first sentence\", \"This is sentence number 2\")\n",
    "print(encoding.tokens)\n",
    "print(encoding.ids)\n",
    "print(encoding.type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bcc5ff",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Using our custom tokenizer with a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "278abcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "model_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=custom_tokenizer,\n",
    "    unk_token=unk_token,\n",
    "    pad_token=pad_token,\n",
    "    cls_token=cls_token,\n",
    "    sep_token=sep_token,\n",
    "    mask_token=mask_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3be8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batch = [\"To be or not to be.\", \"It was the best of times.\", \"Call me Ishmael.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e89f66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_tokenizer(text_batch, padding=True, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a42cb05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py:39: FutureWarning: Pass token='my_custom_tokenizer' as keyword args. From version 0.7 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/huggingface_hub/hf_api.py:596: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/cakiki/my_custom_tokenizer into local empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/cakiki/my_custom_tokenizer\n",
      "   0816225..b2f2f21  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/cakiki/my_custom_tokenizer/commit/b2f2f216f01507f9a32ba6bc2976e126a499d4f5'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tokenizer.push_to_hub(repo_path_or_name=\"my_custom_tokenizer\", \n",
    "                            use_auth_token=True, use_temp_dir=True,\n",
    "                           commit_message=\"6_000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6646d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center;\">ðŸ¤— Datasets</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696eb2e2",
   "metadata": {},
   "source": [
    "<table><thead><tr><th align=\"center\">Data format</th> <th align=\"center\">Loading script</th> <th align=\"center\">Example</th></tr></thead> <tbody><tr><td align=\"center\">CSV &amp; TSV</td> <td align=\"center\"><code>csv</code></td> <td align=\"center\"><code>load_dataset(\"csv\", data_files=\"my_file.csv\")</code></td></tr> <tr><td align=\"center\">Text files</td> <td align=\"center\"><code>text</code></td> <td align=\"center\"><code>load_dataset(\"text\", data_files=\"my_file.txt\")</code></td></tr> <tr><td align=\"center\">JSON &amp; JSON Lines</td> <td align=\"center\"><code>json</code></td> <td align=\"center\"><code>load_dataset(\"json\", data_files=\"my_file.jsonl\")</code></td></tr> <tr><td align=\"center\">Pickled DataFrames</td> <td align=\"center\"><code>pandas</code></td> <td align=\"center\"><code>load_dataset(\"pandas\", data_files=\"my_dataframe.pkl\")</code></td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ce34bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center;\">ðŸ¤— Transformers</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1dcd42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9b1bafa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center;\">Case-study: ðŸ“œ Scientific Paper Retrieval</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa258f94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center;\">(Re)sources</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5d966",
   "metadata": {},
   "source": [
    "- https://github.com/nlp-with-transformers/notebooks\n",
    "\n",
    "- https://github.com/huggingface/course\n",
    "\n",
    "\n",
    "<center><a href=\"https://www.oreilly.com/library/view/natural-language-processing/9781098103231/\"><img src=\"images/book_cover.png\" width=500></a></center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
