{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c5b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from huggingface_hub import notebook_login\n",
    "import os\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855fb9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77716564",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center;\">A Whirlwind Tour of the ü§ó Hugging Face Ecosystem</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec11d2af",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39cc27f",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align:center;\"><b>Christopher Akiki</b></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef876093",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<p style=\"text-align:center;font-style: italic\">Figures in these slides reproduced under the Apache License from <a href=\"https://www.oreilly.com/library/view/natural-language-processing/9781098103231/\">Natural Language Processing with Transformers</a> published by O'Reilly Media, Inc.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37e4175",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><a href=\"https://huggingface.co\"><img src=\"images/chapter01_hf-ecosystem.png\" width=800></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb9897",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"images/chapter02_hf-libraries.png\" width=1800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdfbbea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center;\">ü§ó Pipelines</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32225148",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa0a34",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers.pipelines import get_supported_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e706de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_supported_tasks())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a712fdfd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "<center><img src=\"images/gewandhaus_review.png\" width=900></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21dcda6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"One of the best orchestra in the world. I came to Leipzig\\\n",
    "            mainly to have one experience with Gewanhaus Leipzig Orchestra. \n",
    "            Under the baton of Maestro Andris Nelsons, Bruckner symphony #8 was so affection. \n",
    "            The acustic and layout of the concert hall is nice.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383d0e7e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868326b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline(\"text-classification\", \n",
    "             model='distilbert-base-uncased-finetuned-sst-2-english', device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891c8038",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = p(text)\n",
    "outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca993ce3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Named-Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aeeba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline(\"ner\", aggregation_strategy=\"simple\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", \n",
    "             device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8e4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = p(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf043b0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ae948",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40b4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['What city did I visit?', \n",
    "             'Why did I visit Leipzig?',\n",
    "             'What music did the orchestra play?',\n",
    "             'Who lead the orchestra?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd580a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = p(question=questions, context=text)\n",
    "with pd.option_context('display.max_colwidth', -1):\n",
    "    display(pd.DataFrame(zip(questions, [o['answer'] for o in outputs]), columns=['Question', 'Answer']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203bbce4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0caab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline(\"translation_en_to_de\", \n",
    "             model=\"Helsinki-NLP/opus-mt-en-de\", device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4076c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = p(text, clean_up_tokenization_spaces=True)\n",
    "print(outputs[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb6157",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center;\">ü§ó Tokenizers</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdac586",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"images/tokenization_pipeline.svg\" width=1200></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b370ce",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e5186",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(nltk.corpus.gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d39c6f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "moby_dick_raw = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc19fc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "size = len(moby_dick_raw.encode())\n",
    "print(f\"{size/1024**2:.2f} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca45ab2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, normalizers, pre_tokenizers, processors\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers.trainers import WordPieceTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313154cf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "unk_token = \"[UNK]\"\n",
    "pad_token = \"[PAD]\"\n",
    "cls_token = \"[CLS]\" \n",
    "sep_token = \"[SEP]\"\n",
    "mask_token = \"[MASK]\"\n",
    "special_tokens = [unk_token, pad_token, cls_token, sep_token, mask_token]\n",
    "vocab_size = 6_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c87d4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# WordPiece Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea08735",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "custom_tokenizer = Tokenizer(WordPiece(unk_token=unk_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc53c243",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Sequence of Normalizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3889c0",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "custom_normalizer = normalizers.Sequence(\n",
    "            [normalizers.NFKD(), normalizers.Lowercase(), normalizers.StripAccents()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebac3da",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Sequence of Pretokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586aa00b",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "custom_pre_tokenizer = pre_tokenizers.Sequence(\n",
    "            [pre_tokenizers.WhitespaceSplit(), pre_tokenizers.Punctuation()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0bec5b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# WordPiece Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b3defc",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "custom_trainer = WordPieceTrainer(vocab_size=vocab_size, special_tokens=special_tokens, show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca3e7df",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "custom_tokenizer.normalizer = custom_normalizer\n",
    "custom_tokenizer.pre_tokenizer = custom_pre_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e99d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "custom_tokenizer.train_from_iterator([moby_dick_raw], trainer=custom_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e8730",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f9099",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = custom_tokenizer.encode(\"Let us test this tokenizer\")\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78244dfc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "cls_token_id = custom_tokenizer.token_to_id(cls_token)\n",
    "sep_token_id = custom_tokenizer.token_to_id(sep_token)\n",
    "\n",
    "custom_post_processor = processors.TemplateProcessing(\n",
    "    single=f\"{cls_token}:0 $A:0 {sep_token}:0\",\n",
    "    pair=f\"{cls_token}:0 $A:0 {sep_token}:0 $B:1 {sep_token}:1\",\n",
    "    special_tokens=[(cls_token, cls_token_id), (sep_token, sep_token_id)],\n",
    ")\n",
    "\n",
    "custom_tokenizer.post_processor = custom_post_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29871967",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = custom_tokenizer.encode(\"Let us test this tokenizer\")\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f73fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = custom_tokenizer.encode(\"This is the first sentence\", \"This is sentence number 2\")\n",
    "print(encoding.tokens)\n",
    "print(encoding.ids)\n",
    "print(encoding.type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bcc5ff",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Using our custom tokenizer with a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278abcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "model_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=custom_tokenizer,\n",
    "    unk_token=unk_token,\n",
    "    pad_token=pad_token,\n",
    "    cls_token=cls_token,\n",
    "    sep_token=sep_token,\n",
    "    mask_token=mask_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3be8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batch = [\"To be or not to be.\", \"It was the best of times.\", \"Call me Ishmael.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e89f66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_tokenizer(text_batch, padding=True, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6646d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center;\">ü§ó Datasets</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe0498b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Apache Arrow backend ‚û°Ô∏è Low RAM use\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "import os; import psutil; import timeit\n",
    "from datasets import load_dataset\n",
    "\n",
    "mem_before = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\n",
    "wiki = load_dataset(\"wikipedia\", \"20220301.en\", split=\"train\")\n",
    "mem_after = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\n",
    "\n",
    "print(f\"RAM memory used: {(mem_after - mem_before)} MB\")\n",
    "\n",
    "*****RAM memory used: 50 MB*****\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4120c82d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# Apache Arrow Backend ‚û°Ô∏è Fast Iteration\n",
    "<br>\n",
    "\n",
    "```python\n",
    "s = \"\"\"batch_size = 1000\n",
    "for i in range(0, len(wiki), batch_size):\n",
    "    batch = wiki[i:i + batch_size]\n",
    "\"\"\"\n",
    "time = timeit.timeit(stmt=s, number=1, globals=globals())\n",
    "print(f\"Time to iterate over the {wiki.dataset_size >> 30}GB dataset: {time:.1f} sec, \"\n",
    "      f\"ie. {float(wiki.dataset_size >> 27)/time:.1f} Gb/s\")\n",
    "\n",
    "*****Time to iterate over the 18 GB dataset: 70.5 sec, ie. 2.1 Gb/s*****\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35edb3d5",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import list_datasets, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e617d8",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "all_datasets = list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796783c5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "[d for d in all_datasets if \"emotion\" in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a82276",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "emotions = load_dataset(\"emotion\")\n",
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09027039",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(emotions['train'].info.description)\n",
    "print(125*\"*\")\n",
    "print(emotions['train'].citation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e930fbc6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = emotions[\"train\"]\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.features['label'].int2str(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85578e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f457b4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train_ds[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482b0a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ccb43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ds[:10]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298305a1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def compute_tweet_length(row):\n",
    "    return {\"tweet_length\": len(row['text'].split())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c5e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(compute_tweet_length, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a0a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.push_to_hub('emotion-with-length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8217eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.sort(\"tweet_length\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a844f83",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def batched_compute_tweet_length(batch_of_rows):\n",
    "    return {\"tweet_length\": [len(text.split()) for text in batch_of_rows['text']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds.map(batched_compute_tweet_length, batched=True, batch_size=2000, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e4622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time train_ds.map(compute_tweet_length, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13589219",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time train_ds.map(batched_compute_tweet_length, batched=True, batch_size=2000, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f775ee0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train_ds.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c83245",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.remove_columns('tweet_length')\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e963d633",
   "metadata": {},
   "source": [
    "# Loading your own files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696eb2e2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table><thead><tr><th align=\"center\">Data format</th> <th align=\"center\">Loading script</th> <th align=\"center\">Example</th></tr></thead> <tbody><tr><td align=\"center\">CSV &amp; TSV</td> <td align=\"center\"><code>csv</code></td> <td align=\"center\"><code>load_dataset(\"csv\", data_files=\"my_file.csv\")</code></td></tr> <tr><td align=\"center\">Text files</td> <td align=\"center\"><code>text</code></td> <td align=\"center\"><code>load_dataset(\"text\", data_files=\"my_file.txt\")</code></td></tr> <tr><td align=\"center\">JSON &amp; JSON Lines</td> <td align=\"center\"><code>json</code></td> <td align=\"center\"><code>load_dataset(\"json\", data_files=\"my_file.jsonl\")</code></td></tr> <tr><td align=\"center\">Pickled DataFrames</td> <td align=\"center\"><code>pandas</code></td> <td align=\"center\"><code>load_dataset(\"pandas\", data_files=\"my_dataframe.pkl\")</code></td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4455481",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f270b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions.set_format(type=\"pandas\")\n",
    "emotions_df = emotions['train'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_df['label_name'] = emotions_df['label'].apply(lambda x: train_ds.features['label'].int2str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d3a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_df['text'].str.split().apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc53eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48402a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ce34bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center;\">ü§ó Transformers</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2317a04",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"images/chapter03_transformers-compact.png\" width=500></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947ac7a5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification, DataCollatorWithPadding\n",
    "\n",
    "model_checkpoint = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173cd882",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br><center><img src=\"images/chapter04_bert-body-head.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a71297",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Transfer Learning via Feature Extraction (Homework)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dde6e2e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center><img src=\"images/chapter02_encoder-feature-based.png\" width=1000></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deedcc77",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Transfer Learning via Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752b5e0a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center><img src=\"images/chapter02_encoder-fine-tuning.png\" width=1000></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3af395a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db7f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer([\"This is a test\", \"This is another test\", \"cat\"], return_tensors=\"tf\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31118f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4c7be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_ds = train_ds.map(tokenize, batched=True, batch_size=None)\n",
    "tokenized_val_ds = emotions['validation'].map(tokenize, batched=True, batch_size=None)\n",
    "tokenizer_test_ds = emotions['test'].map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a7c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7c83a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "\n",
    "tf_train_dataset = tokenized_train_ds.to_tf_dataset(columns=tokenizer.model_input_names, \n",
    "                                                    label_cols=['label'], shuffle=True, batch_size=BATCH_SIZE,\n",
    "                                                    collate_fn=data_collator\n",
    "                                                   )\n",
    "\n",
    "tf_val_dataset = tokenized_val_ds.to_tf_dataset(columns=tokenizer.model_input_names, \n",
    "                                                    label_cols=['label'], shuffle=False, batch_size=BATCH_SIZE,\n",
    "                                                    collate_fn=data_collator\n",
    "                                                   )\n",
    "\n",
    "tf_test_dataset = tokenizer_test_ds.to_tf_dataset(columns=tokenizer.model_input_names, \n",
    "                                                    label_cols=['label'], shuffle=False, batch_size=BATCH_SIZE,\n",
    "                                                    collate_fn=data_collator\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9026bacb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for i in tf_train_dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db834ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained(model_checkpoint, \n",
    "                                                              num_labels=train_ds.features['label'].num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783a5e8d",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /tf/model/logs --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640f36e9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./model/logs\")\n",
    "\n",
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir=\"./model\",\n",
    "    tokenizer=tokenizer,\n",
    "    hub_model_id=f\"{model_checkpoint}-finetuned-tweet-sentiment\",\n",
    ")\n",
    "\n",
    "callbacks = [tensorboard_callback, push_to_hub_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2dbc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=tf.metrics.SparseCategoricalAccuracy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc0f1e",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(tf_train_dataset, validation_data=tf_val_dataset, epochs=3, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad932263",
   "metadata": {},
   "outputs": [],
   "source": [
    " _, accuracy = model.evaluate(tf_test_dataset)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e772aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b600ec6a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-classification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcakiki/distilbert-base-uncased-finetuned-tweet-sentiment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pipelines/__init__.py:549\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m# Infer the framework from the model\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;66;03m# Forced if framework already defined, inferred if it's None\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# Will load the correct model if possible\u001b[39;00m\n\u001b[1;32m    548\u001b[0m model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 549\u001b[0m framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    561\u001b[0m load_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(model_config) \u001b[38;5;129;01min\u001b[39;00m TOKENIZER_MAPPING \u001b[38;5;129;01mor\u001b[39;00m model_config\u001b[38;5;241m.\u001b[39mtokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:246\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load the model with Tensorflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m     )\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 246\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    248\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py:446\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    445\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/modeling_tf_utils.py:1707\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1698\u001b[0m     archive_file \u001b[38;5;241m=\u001b[39m hf_bucket_url(\n\u001b[1;32m   1699\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   1700\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1701\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   1702\u001b[0m         mirror\u001b[38;5;241m=\u001b[39mmirror,\n\u001b[1;32m   1703\u001b[0m     )\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1706\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m-> 1707\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m        \u001b[49m\u001b[43marchive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1716\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m   1719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   1720\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1721\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken having permission to this repo with `use_auth_token` or log in with `huggingface-cli \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogin` and pass `use_auth_token=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1724\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py:282\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    278\u001b[0m     local_files_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m url_or_filename\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py:585\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m temp_file_manager() \u001b[38;5;28;01mas\u001b[39;00m temp_file:\n\u001b[1;32m    583\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in cache or force_download set to True, downloading to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemp_file\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 585\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstoring \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    588\u001b[0m os\u001b[38;5;241m.\u001b[39mreplace(temp_file\u001b[38;5;241m.\u001b[39mname, cache_path)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py:423\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resume_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    422\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRange\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresume_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 423\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m _raise_for_status(r)\n\u001b[1;32m    425\u001b[0m content_length \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/api.py:75\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/api.py:60\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:533\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m: allow_redirects,\n\u001b[1;32m    531\u001b[0m }\n\u001b[1;32m    532\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 533\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:646\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    645\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 646\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    649\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/adapters.py:439\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 439\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py:1040\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n\u001b[1;32m   1043\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1044\u001b[0m         (\n\u001b[1;32m   1045\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnverified HTTPS request is being made to host \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         InsecureRequestWarning,\n\u001b[1;32m   1051\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connection.py:358\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m    360\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocket_options\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout),\n\u001b[1;32m    183\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m     84\u001b[0m         sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 85\u001b[0m     \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sock\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "p = pipeline(\"text-classification\", model='cakiki/distilbert-base-uncased-finetuned-tweet-sentiment', device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface.load(\"huggingface/cakiki/distilbert-base-uncased-finetuned-tweet-sentiment\").launch(share=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa258f94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center;\">(Re)sources</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5d966",
   "metadata": {},
   "source": [
    "- https://github.com/nlp-with-transformers/notebooks\n",
    "\n",
    "- https://huggingface.co/docs\n",
    "\n",
    "- https://github.com/huggingface/course / https://github.com/huggingface/notebooks\n",
    "\n",
    "- https://github.com/NielsRogge/Transformers-Tutorials\n",
    "\n",
    "<center><a href=\"https://www.oreilly.com/library/view/natural-language-processing/9781098103231/\"><img src=\"images/book_cover.png\" width=400></a></center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
